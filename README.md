# üöÄ NER Web Service

## üìå –û–ø–∏—Å–∞–Ω–∏–µ
–°–µ—Ä–≤–∏—Å –¥–ª—è **—Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è —Å—É—â–Ω–æ—Å—Ç–µ–π –≤ —Ç–µ–∫—Å—Ç–µ** (–±—Ä–µ–Ω–¥—ã, —Ç–∏–ø—ã —Ç–æ–≤–∞—Ä–æ–≤, —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏). –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –∏–Ω—Ç–µ—Ä–≤–∞–ª–æ–≤ —Å—É—â–Ω–æ—Å—Ç–µ–π —Å —Ç–∏–ø–∞–º–∏.

- –í–≤–æ–¥ —á–µ—Ä–µ–∑ REST API
- –í—ã—Å–æ–∫–æ–ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω—ã–π –±–∞—Ç—á–∏–Ω–≥ (–æ—á–µ—Ä–µ–¥—å) –¥–ª—è –Ω–∞–≥—Ä—É–∑–∫–∏
- –ü–æ—Å—Ç–ø—Ä–æ—Ü–µ—Å—Å–∏–Ω–≥ –ø—Ä–∞–≤–∏–ª –¥–ª—è –ø–æ–≤—ã—à–µ–Ω–∏—è –∫–∞—á–µ—Å—Ç–≤–∞

---

## üõ† –¢–µ—Ö–Ω–æ–ª–æ–≥–∏–∏
- Python 3.10+
- FastAPI + Uvicorn
- Transformers (—Ç–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è) + ONNX Runtime (–∏–Ω—Ñ–µ—Ä–µ–Ω—Å)
- Docker, docker-compose (GPU)

–ú–æ–¥–µ–ª—å –∏ —Ç–æ–∫–µ–Ω–∞–π–∑–µ—Ä –ª–µ–∂–∞—Ç –≤ `./models/ner_xlmr_wordlevel_entity` (—Ä—è–¥–æ–º —Å —ç—Ç–∏–º README).

---

## ‚öôÔ∏è –¢—Ä–µ–±–æ–≤–∞–Ω–∏—è
- Linux/Mac/Windows
- Python 3.10+
- –û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ: NVIDIA GPU + Docker/NVIDIA Container Toolkit

–ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–µ —Ä–µ—Å—É—Ä—Å—ã: 2 CPU, 4 GB RAM, ~2 GB –¥–∏—Å–∫–∞.

---

## üöÄ –ë—ã—Å—Ç—Ä—ã–π —Å—Ç–∞—Ä—Ç (–ª–æ–∫–∞–ª—å–Ω–æ, CPU)
–ó–∞–ø—É—Å–∫–∞–π—Ç–µ –∏–∑ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ `repo/`.

```bash
cd repo
python -m venv .venv
source .venv/bin/activate  # Windows: .venv\\Scripts\\activate
pip install -r requirements.cpu.txt

# –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –æ—Ç–∫–ª—é—á–∏—Ç—å –ø–∞—Ä–∞–ª–ª–µ–ª–∏–∑–º —Ç–æ–∫–µ–Ω–∞–π–∑–µ—Ä–∞ HF
export TOKENIZERS_PARALLELISM=false

# –ó–∞–ø—É—Å–∫ API (–æ–±—ä–µ–∫—Ç –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è: app.main:api)
uvicorn app.main:api --host 0.0.0.0 --port 8000
```

–ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–¥–æ—Ä–æ–≤—å—è:
```bash
curl http://localhost:8000/health
```

–ó–∞–ø—Ä–æ—Å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π:
```bash
curl -X POST http://localhost:8000/api/predict \
  -H 'Content-Type: application/json' \
  -d '{"input":"–ú–æ–ª–æ–∫–æ –ü—Ä–æ—Å—Ç–æ–∫–≤–∞—à–∏–Ω–æ 2% 1–ª"}'
```

–û—Ç–≤–µ—Ç (–ø—Ä–∏–º–µ—Ä):
```json
[
  {"start_index": 0, "end_index": 6, "entity": "BRAND"}
]
```

–ü—Ä–∏–º–µ—á–∞–Ω–∏—è:
- –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é —Å–µ—Ä–≤–∏—Å –≤–æ–∑—å–º—ë—Ç –º–æ–¥–µ–ª—å –∏–∑ `models/ner_xlmr_wordlevel_entity` (–ª–æ–∫–∞–ª—å–Ω–æ –ø—É—Ç—å —Ä–µ–∑–æ–ª–≤–∏—Ç—Å—è –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ –∫–æ—Ä–Ω—è —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è).
- –ú–æ–∂–Ω–æ –ø–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å —á–µ—Ä–µ–∑ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è `MODEL_DIR`, `LABELS_PATH`.

---

## üß∞ –ü–∞–∫–µ—Ç–Ω–∞—è –∏–Ω—Ñ–µ—Ä–µ–Ω—Ü–∏—è (CLI)
–ï—Å—Ç—å —É—Ç–∏–ª–∏—Ç–∞ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ CSV –ø–∞—á–∫–∞–º–∏ (`repo/app/infer.py`).

–í–∞—Ä–∏–∞–Ω—Ç A (–∑–∞–ø—É—Å–∫ –∏–∑ –∫–æ—Ä–Ω—è —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è):
```bash
python -m repo.app.infer \
  --csv-in train/data/submission.csv \
  --csv-out submission_pred.csv \
  --batch-size 16
```

–í–∞—Ä–∏–∞–Ω—Ç B (–∑–∞–ø—É—Å–∫ –∏–∑ `repo/`):
```bash
cd repo
python -m app.infer --csv-in ../train/data/submission.csv --csv-out ../submission_pred.csv --batch-size 16
```

–í—ã—Ö–æ–¥–Ω–æ–π CSV —Å–æ–¥–µ—Ä–∂–∏—Ç –∫–æ–ª–æ–Ω–∫–∏: `sample;annotation`.

---

## üê≥ Docker (CPU)
–†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è —Å–æ–±–∏—Ä–∞—Ç—å –∏–∑ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ `repo/` —Å —É–∫–∞–∑–∞–Ω–∏–µ–º Dockerfile –≤–Ω—É—Ç—Ä–∏ `repo/docker`.

```bash
cd repo
docker build -t ner-cpu -f docker/Dockerfile.cpu .

# –ú–æ–Ω—Ç–∏—Ä—É–µ–º –º–æ–¥–µ–ª—å –≤–Ω—É—Ç—Ä—å –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞ –≤ /models
docker run --rm -p 8000:8000 \
  -e TOKENIZERS_PARALLELISM=false \
  -e MODEL_DIR=/models/ner_xlmr_wordlevel_entity \
  -e LABELS_PATH=/models/ner_xlmr_wordlevel_entity/labels.txt \
  -v "$(pwd)/models:/models:ro" \
  ner-cpu
```

---

## ‚ö°Ô∏è Docker (GPU)
–¢—Ä–µ–±—É–µ—Ç—Å—è NVIDIA –¥—Ä–∞–π–≤–µ—Ä –∏ NVIDIA Container Toolkit.

```bash
cd repo
docker build -t ner-gpu -f docker/Dockerfile.gpu .

docker run --rm -p 8000:8000 --gpus all \
  -e TOKENIZERS_PARALLELISM=false \
  -e MODEL_DIR=/models/ner_xlmr_wordlevel_entity \
  -e LABELS_PATH=/models/ner_xlmr_wordlevel_entity/labels.txt \
  -e NVIDIA_VISIBLE_DEVICES=all \
  -v "$(pwd)/models:/models:ro" \
  ner-gpu
```

–ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–∞ ‚Äî docker-compose (GPU –ø—Ä–æ—Ñ–∏–ª—å):
```bash
cd repo
docker compose --profile gpu up --build -d
```

Compose-—Ñ–∞–π–ª –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —Å–º–æ–Ω—Ç–∏—Ä—É–µ—Ç `../models` –≤ `/models` –∏ –≤—ã—Å—Ç–∞–≤–∏—Ç –Ω—É–∂–Ω—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ.

---

## üß© docker-compose (CPU –ø—Ä–æ—Ñ–∏–ª—å)
```bash
cd repo
docker compose --profile cpu up --build -d
```

–°–µ—Ä–≤–∏—Å –∏—Å–ø–æ–ª—å–∑—É–µ—Ç `docker/Dockerfile.cpu`, –º–æ–Ω—Ç–∏—Ä—É–µ—Ç –ª–æ–∫–∞–ª—å–Ω—ã–µ `../models` –≤ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä `/models` –∏ –ø—Ä–æ–±—Ä–∞—Å—ã–≤–∞–µ—Ç –ø–æ—Ä—Ç `8000`.

---

## üîß –ü–æ–ª–µ–∑–Ω—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è
- `MODEL_DIR` ‚Äî –ø—É—Ç—å –∫ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –º–æ–¥–µ–ª–∏ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: –ª–æ–∫–∞–ª—å–Ω–æ `./models/ner_xlmr_wordlevel_entity`, –≤ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–µ –æ–∂–∏–¥–∞–µ—Ç—Å—è `/models/...`).
- `LABELS_PATH` ‚Äî –ø—É—Ç—å –∫ `labels.txt`.
- `MAX_SEQ_LEN` ‚Äî –º–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 256 –ª–æ–∫–∞–ª—å–Ω–æ; –≤ compose –ø—Ä–∏–º–µ—Ä 64).
- `USE_QUEUE` ‚Äî –≤–∫–ª—é—á–∏—Ç—å –±–∞—Ç—á–∏–Ω–≥ –∑–∞–ø—Ä–æ—Å–æ–≤ (`true/false`).
- `BATCH_MAX_SIZE`, `BATCH_TIMEOUT_MS` ‚Äî –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –±–∞—Ç—á–∏–Ω–≥–∞.
- `REQUEST_TIMEOUT_MS` ‚Äî —Ç–∞–π–º–∞—É—Ç –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∑–∞–ø—Ä–æ—Å–∞.
- `ORT_FORCE_CPU` ‚Äî —Ñ–æ—Ä—Å–∏—Ä–æ–≤–∞—Ç—å CPU –≤ ONNX Runtime (`1`/`0`).
- `TOKENIZERS_PARALLELISM` ‚Äî –≤—ã–∫–ª—é—á–∏—Ç—å –≤–∞—Ä–Ω–∏–Ω–≥–∏ HF —Ç–æ–∫–µ–Ω–∞–π–∑–µ—Ä–∞ (`false`).

---

## üß™ –≠–Ω–¥–ø–æ–∏–Ω—Ç—ã
- `GET /health` ‚Äî —Å—Ç–∞—Ç—É—Å —Å–µ—Ä–≤–∏—Å–∞
- `POST /api/predict` ‚Äî —Ç–µ–ª–æ: `{ "input": "—Å—Ç—Ä–æ–∫–∞" }`; –æ—Ç–≤–µ—Ç ‚Äî —Å–ø–∏—Å–æ–∫ `{ start_index, end_index, entity }`.

---

## üèó –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ (–≤–∫—Ä–∞—Ç—Ü–µ)
1. –¢–µ–∫—Å—Ç ‚Üí –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è/–º–∞—Å–∫–∏—Ä–æ–≤–∞–Ω–∏–µ (–ø–æ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º)
2. –¢–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è (Transformers)
3. –ò–Ω—Ñ–µ—Ä–µ–Ω—Å ONNX Runtime (CPU/GPU)
4. –ü–æ—Å—Ç–ø—Ä–æ—Ü–µ—Å—Å–∏–Ω–≥ –ø—Ä–∞–≤–∏–ª (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
5. JSON-–æ—Ç–≤–µ—Ç —Å–æ —Å–ø–∏—Å–∫–æ–º —Å—É—â–Ω–æ—Å—Ç–µ–π


