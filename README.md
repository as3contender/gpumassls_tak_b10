# üöÄ NER Web Service

## üìå –û–ø–∏—Å–∞–Ω–∏–µ
–°–µ—Ä–≤–∏—Å –¥–ª—è **—Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è —Å—É—â–Ω–æ—Å—Ç–µ–π –≤ —Ç–µ–∫—Å—Ç–µ** (–±—Ä–µ–Ω–¥—ã, —Ç–∏–ø—ã —Ç–æ–≤–∞—Ä–æ–≤, —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏). –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –∏–Ω—Ç–µ—Ä–≤–∞–ª–æ–≤ —Å—É—â–Ω–æ—Å—Ç–µ–π —Å —Ç–∏–ø–∞–º–∏.

- –í–≤–æ–¥ —á–µ—Ä–µ–∑ REST API
- –í—ã—Å–æ–∫–æ–ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω—ã–π –±–∞—Ç—á–∏–Ω–≥ (–æ—á–µ—Ä–µ–¥—å) –¥–ª—è –Ω–∞–≥—Ä—É–∑–∫–∏
- –ü–æ—Å—Ç–ø—Ä–æ—Ü–µ—Å—Å–∏–Ω–≥ –ø—Ä–∞–≤–∏–ª –¥–ª—è –ø–æ–≤—ã—à–µ–Ω–∏—è –∫–∞—á–µ—Å—Ç–≤–∞

---

## üõ† –¢–µ—Ö–Ω–æ–ª–æ–≥–∏–∏
- Python 3.10+
- FastAPI + Uvicorn
- Transformers (—Ç–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è) + ONNX Runtime (–∏–Ω—Ñ–µ—Ä–µ–Ω—Å)
- Docker, docker-compose (GPU)

–ú–æ–¥–µ–ª—å –∏ —Ç–æ–∫–µ–Ω–∞–π–∑–µ—Ä –ª–µ–∂–∞—Ç –≤ `./models/ner_xlmr_wordlevel_entity` (—Ä—è–¥–æ–º —Å —ç—Ç–∏–º README).

---

## ‚öôÔ∏è –¢—Ä–µ–±–æ–≤–∞–Ω–∏—è
- Linux/Mac/Windows
- Python 3.10+
- –û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ: NVIDIA GPU + Docker/NVIDIA Container Toolkit

–ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–µ —Ä–µ—Å—É—Ä—Å—ã: 2 CPU, 4 GB RAM, ~2 GB –¥–∏—Å–∫–∞.

---

## ‚ö° –ë—ã—Å—Ç—Ä—ã–π —Å—Ç–∞—Ä—Ç (Docker, CPU)
```bash
# –ö–ª–æ–Ω–∏—Ä—É–µ–º —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π –∏ –ø–æ–¥—Ç—è–≥–∏–≤–∞–µ–º –º–æ–¥–µ–ª—å —á–µ—Ä–µ–∑ Git LFS
git clone <URL_–†–ï–ü–û–ó–ò–¢–û–†–ò–Ø>
git lfs install && git lfs pull

# –ü–æ–¥–Ω–∏–º–∞–µ–º —Å–µ—Ä–≤–∏—Å –≤ Docker (CPU –ø—Ä–æ—Ñ–∏–ª—å)
docker compose --profile cpu up --build -d

# –ü—Ä–æ–≤–µ—Ä–∫–∞
curl http://localhost:8000/health
curl -X POST http://localhost:8000/api/predict \
  -H 'Content-Type: application/json' \
  -d '{"input":"–∫–µ—Ñ–∏—Ä 3.2% –ø—Ä–æ—Å—Ç–æ–∫–≤–∞—à–∏–Ω–æ 930 –º–ª"}'
```

---

## üöÄ –ë—ã—Å—Ç—Ä—ã–π —Å—Ç–∞—Ä—Ç (–ª–æ–∫–∞–ª—å–Ω–æ, CPU)
–ó–∞–ø—É—Å–∫–∞–π—Ç–µ –∏–∑ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ `repo/`.

```bash
cd repo
python -m venv .venv
source .venv/bin/activate  # Windows: .venv\\Scripts\\activate
pip install -r requirements.cpu.txt

# –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –æ—Ç–∫–ª—é—á–∏—Ç—å –ø–∞—Ä–∞–ª–ª–µ–ª–∏–∑–º —Ç–æ–∫–µ–Ω–∞–π–∑–µ—Ä–∞ HF
export TOKENIZERS_PARALLELISM=false

# –ó–∞–ø—É—Å–∫ API (–æ–±—ä–µ–∫—Ç –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è: app.main:api)
uvicorn app.main:api --host 0.0.0.0 --port 8000
```

–ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–¥–æ—Ä–æ–≤—å—è:
```bash
curl http://localhost:8000/health
```

–ó–∞–ø—Ä–æ—Å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π:
```bash
curl -X POST http://localhost:8000/api/predict \
  -H 'Content-Type: application/json' \
  -d '{"input":"–ú–æ–ª–æ–∫–æ –ü—Ä–æ—Å—Ç–æ–∫–≤–∞—à–∏–Ω–æ 2% 1–ª"}'
```

–û—Ç–≤–µ—Ç (–ø—Ä–∏–º–µ—Ä):
```json
[
  {"start_index": 0, "end_index": 6, "entity": "BRAND"}
]
```

–ü—Ä–∏–º–µ—á–∞–Ω–∏—è:
- –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é —Å–µ—Ä–≤–∏—Å –≤–æ–∑—å–º—ë—Ç –º–æ–¥–µ–ª—å –∏–∑ `./models/ner_xlmr_wordlevel_entity`.
- –ú–æ–∂–Ω–æ –ø–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å —á–µ—Ä–µ–∑ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è `MODEL_DIR`, `LABELS_PATH`.

---

## üß∞ –ü–∞–∫–µ—Ç–Ω–∞—è –∏–Ω—Ñ–µ—Ä–µ–Ω—Ü–∏—è (CLI)
–ï—Å—Ç—å —É—Ç–∏–ª–∏—Ç–∞ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ CSV –ø–∞—á–∫–∞–º–∏ (`repo/app/infer.py`).

–í–∞—Ä–∏–∞–Ω—Ç A (–∑–∞–ø—É—Å–∫ –∏–∑ –∫–æ—Ä–Ω—è —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è):
```bash
python -m repo.app.infer \
  --csv-in train/data/submission.csv \
  --csv-out submission_pred.csv \
  --batch-size 16
```

–í–∞—Ä–∏–∞–Ω—Ç B (–∑–∞–ø—É—Å–∫ –∏–∑ `repo/`):
```bash
cd repo
python -m app.infer --csv-in ../train/data/submission.csv --csv-out ../submission_pred.csv --batch-size 16
```

–í—ã—Ö–æ–¥–Ω–æ–π CSV —Å–æ–¥–µ—Ä–∂–∏—Ç –∫–æ–ª–æ–Ω–∫–∏: `sample;annotation`.

---

## üîé Troubleshooting
- –ú–æ–¥–µ–ª—å –Ω–µ –ø–æ–¥—Ç—è–Ω—É–ª–∞—Å—å (–ø—É—Å—Ç–æ–π `model.onnx`): —É–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω Git LFS –∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–æ `git lfs pull` –≤ `repo/`.
- –ü–æ—Ä—Ç 8000 –∑–∞–Ω—è—Ç: –ø–æ–º–µ–Ω—è–π—Ç–µ –ø–æ—Ä—Ç –≤ –∫–æ–º–∞–Ω–¥–µ –∑–∞–ø—É—Å–∫–∞ –∏–ª–∏ –æ—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –∫–æ–Ω—Ñ–ª–∏–∫—Ç—É—é—â–∏–π –ø—Ä–æ—Ü–µ—Å—Å.
- –ú–µ–¥–ª–µ–Ω–Ω—ã–π —Å—Ç–∞—Ä—Ç: –ø–µ—Ä–≤—ã–π –∑–∞–ø—É—Å–∫ –ø—Ä–æ–≥—Ä–µ–≤–∞–µ—Ç —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä –∏ –≥—Ä–∞—Ñ ONNX; –¥–∞–ª—å–Ω–µ–π—à–∏–µ –∑–∞–ø—Ä–æ—Å—ã –±—ã—Å—Ç—Ä–µ–µ.

## üê≥ Docker (CPU)
–†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è —Å–æ–±–∏—Ä–∞—Ç—å –∏–∑ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ `repo/` —Å —É–∫–∞–∑–∞–Ω–∏–µ–º Dockerfile –≤–Ω—É—Ç—Ä–∏ `repo/docker`.

```bash
cd repo
docker build -t ner-cpu -f docker/Dockerfile.cpu .

# –ú–æ–Ω—Ç–∏—Ä—É–µ–º –º–æ–¥–µ–ª—å –≤–Ω—É—Ç—Ä—å –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞ –≤ /models
docker run --rm -p 8000:8000 \
  -e TOKENIZERS_PARALLELISM=false \
  -e MODEL_DIR=/models/ner_xlmr_wordlevel_entity \
  -e LABELS_PATH=/models/ner_xlmr_wordlevel_entity/labels.txt \
  -v "$(pwd)/models:/models:ro" \
  ner-cpu
```

---

## ‚ö°Ô∏è Docker (GPU)
–¢—Ä–µ–±—É–µ—Ç—Å—è NVIDIA –¥—Ä–∞–π–≤–µ—Ä –∏ NVIDIA Container Toolkit.

```bash
cd repo
docker build -t ner-gpu -f docker/Dockerfile.gpu .

docker run --rm -p 8000:8000 --gpus all \
  -e TOKENIZERS_PARALLELISM=false \
  -e MODEL_DIR=/models/ner_xlmr_wordlevel_entity \
  -e LABELS_PATH=/models/ner_xlmr_wordlevel_entity/labels.txt \
  -e NVIDIA_VISIBLE_DEVICES=all \
  -v "$(pwd)/models:/models:ro" \
  ner-gpu
```

–ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–∞ ‚Äî docker-compose (GPU –ø—Ä–æ—Ñ–∏–ª—å):
```bash
cd repo
docker compose --profile gpu up --build -d
```

Compose-—Ñ–∞–π–ª –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —Å–º–æ–Ω—Ç–∏—Ä—É–µ—Ç `./models` –≤ `/models` –∏ –≤—ã—Å—Ç–∞–≤–∏—Ç –Ω—É–∂–Ω—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ.

---

## üß© docker-compose (CPU –ø—Ä–æ—Ñ–∏–ª—å)
```bash
cd repo
docker compose --profile cpu up --build -d
```

–°–µ—Ä–≤–∏—Å –∏—Å–ø–æ–ª—å–∑—É–µ—Ç `docker/Dockerfile.cpu`, –º–æ–Ω—Ç–∏—Ä—É–µ—Ç –ª–æ–∫–∞–ª—å–Ω—ã–µ `./models` –≤ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä `/models` –∏ –ø—Ä–æ–±—Ä–∞—Å—ã–≤–∞–µ—Ç –ø–æ—Ä—Ç `8000`.

---

## üîß –ü–æ–ª–µ–∑–Ω—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è
- `MODEL_DIR` ‚Äî –ø—É—Ç—å –∫ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –º–æ–¥–µ–ª–∏ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: –ª–æ–∫–∞–ª—å–Ω–æ `./models/ner_xlmr_wordlevel_entity`, –≤ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–µ –æ–∂–∏–¥–∞–µ—Ç—Å—è `/models/...`).
- `LABELS_PATH` ‚Äî –ø—É—Ç—å –∫ `labels.txt`.
- `MAX_SEQ_LEN` ‚Äî –º–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 256 –ª–æ–∫–∞–ª—å–Ω–æ; –≤ compose –ø—Ä–∏–º–µ—Ä 64).
- `USE_QUEUE` ‚Äî –≤–∫–ª—é—á–∏—Ç—å –±–∞—Ç—á–∏–Ω–≥ –∑–∞–ø—Ä–æ—Å–æ–≤ (`true/false`).
- `BATCH_MAX_SIZE`, `BATCH_TIMEOUT_MS` ‚Äî –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –±–∞—Ç—á–∏–Ω–≥–∞.
- `REQUEST_TIMEOUT_MS` ‚Äî —Ç–∞–π–º–∞—É—Ç –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∑–∞–ø—Ä–æ—Å–∞.
- `ORT_FORCE_CPU` ‚Äî —Ñ–æ—Ä—Å–∏—Ä–æ–≤–∞—Ç—å CPU –≤ ONNX Runtime (`1`/`0`).
- `TOKENIZERS_PARALLELISM` ‚Äî –≤—ã–∫–ª—é—á–∏—Ç—å –≤–∞—Ä–Ω–∏–Ω–≥–∏ HF —Ç–æ–∫–µ–Ω–∞–π–∑–µ—Ä–∞ (`false`).

---

## üöö –î–µ–ø–ª–æ–π-—Å–∫—Ä–∏–ø—Ç—ã –∏ .env
–°–∫—Ä–∏–ø—Ç—ã `deploy_cpu.sh` –∏ `deploy_gpu.sh` —á–∏—Ç–∞—é—Ç –∫–æ–Ω—Ñ–∏–≥ –∏–∑ —Ñ–∞–π–ª–∞ `.env` –≤ –ø–∞–ø–∫–µ `repo/` (–µ—Å–ª–∏ –æ–Ω —Å—É—â–µ—Å—Ç–≤—É–µ—Ç):

–ü–µ—Ä–µ–º–µ–Ω–Ω—ã–µ:
- `DEPLOY_USER` ‚Äî –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –Ω–∞ —Å–µ—Ä–≤–µ—Ä–µ (–Ω–∞–ø—Ä–∏–º–µ—Ä, `ubuntu`)
- `DEPLOY_HOST` ‚Äî –∞–¥—Ä–µ—Å —Å–µ—Ä–≤–µ—Ä–∞ (–Ω–∞–ø—Ä–∏–º–µ—Ä, `1.2.3.4`)
- `DEPLOY_PORT` ‚Äî –ø–æ—Ä—Ç –ø—É–±–ª–∏–∫–∞—Ü–∏–∏ API (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é `8000`)

–ü—Ä–∏–º–µ—Ä `.env`:
```
DEPLOY_USER=ubuntu
DEPLOY_HOST=1.2.3.4
DEPLOY_PORT=8000
```

–ó–∞–ø—É—Å–∫ (–∏–∑ `repo/`):
```bash
./deploy_cpu.sh   # –∏–ª–∏ ./deploy_gpu.sh
```


## üß™ –≠–Ω–¥–ø–æ–∏–Ω—Ç—ã
- `GET /health` ‚Äî —Å—Ç–∞—Ç—É—Å —Å–µ—Ä–≤–∏—Å–∞
- `POST /api/predict` ‚Äî —Ç–µ–ª–æ: `{ "input": "—Å—Ç—Ä–æ–∫–∞" }`; –æ—Ç–≤–µ—Ç ‚Äî —Å–ø–∏—Å–æ–∫ `{ start_index, end_index, entity }`.

---

## ‚úÖ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ
–ë—ã—Å—Ç—Ä—ã–µ unit-—Ç–µ—Å—Ç—ã (–º–æ–¥–µ–ª—å –Ω–µ –∑–∞–≥—Ä—É–∂–∞–µ—Ç—Å—è, –ø–æ–¥–º–µ–Ω—è–µ—Ç—Å—è —Å—Ç–∞–±–æ–º):
```bash
cd repo
python -m pip install pytest
pytest -q
```

---

## üìö EDA –∏ –æ–±—É—á–µ–Ω–∏–µ
- EDA –∏ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö: —Å–º. –Ω–æ—É—Ç–±—É–∫ `repo/train/EDA_GENERAYION.ipynb` (–∞–Ω–∞–ª–∏–∑ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–π, –¥–ª–∏–Ω—ã —Ç–µ–∫—Å—Ç–æ–≤, —á–∞—Å—Ç–æ—Ç—ã –º–µ—Ç–æ–∫, sanity-check —Ä–∞–∑–º–µ—Ç–∫–∏).

- –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏: —Å–º. –Ω–æ—É—Ç–±—É–∫ `repo/train/final-v2 (1).ipynb`.
  - –ë–∞–∑–æ–≤–∞—è –º–æ–¥–µ–ª—å: `xlm-roberta-large` (Token Classification)
  - –¢–æ–∫–µ–Ω–∞–π–∑–µ—Ä: `AutoTokenizer.from_pretrained(MODEL_NAME)`
  - –¢–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏: `max_length=128`
  - –ì–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã (TrainingArguments):
    - `learning_rate=3e-5`
    - `per_device_train_batch_size=16`
    - `num_train_epochs=12`
  - –ö–∞—Å—Ç–æ–º–Ω—ã–π —Ç—Ä–µ–Ω–µ—Ä: `FocalTrainerWithOffsets(Trainer)` + `DataCollatorForTokenClassification`
  - –≠–∫—Å–ø–æ—Ä—Ç –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–æ–≤:
    - —á–µ–∫–ø–æ–∏–Ω—Ç –∏ —Ç–æ–∫–µ–Ω–∞–π–∑–µ—Ä ‚Üí `./ner_xlmr_wordlevel_entity_best`
    - TorchScript ‚Üí `model_torchscript.pt`
    - ONNX ‚Üí `model.onnx`
- –ò–Ω—Ñ–µ—Ä–µ–Ω—Å:
  - –í –Ω–æ—É—Ç–±—É–∫–µ: `MAX_LENGTH=512`; –≤ —Å–µ—Ä–≤–∏—Å–µ: `max_seq_len=256` (—Å–º. `app/settings.py`) –¥–ª—è —Å–∫–æ—Ä–æ—Å—Ç–∏.
  - –í –ø—Ä–æ–¥–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è `ONNX Runtime` (—Å–º. `app/runtime.py`), –º–æ–¥–µ–ª—å –∏–∑ `repo/models/ner_xlmr_wordlevel_entity`.

## üèó –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ (–≤–∫—Ä–∞—Ç—Ü–µ)
1. –¢–µ–∫—Å—Ç ‚Üí –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è/–º–∞—Å–∫–∏—Ä–æ–≤–∞–Ω–∏–µ (–ø–æ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º)
2. –¢–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è (Transformers)
3. –ò–Ω—Ñ–µ—Ä–µ–Ω—Å ONNX Runtime (CPU/GPU)
4. –ü–æ—Å—Ç–ø—Ä–æ—Ü–µ—Å—Å–∏–Ω–≥ –ø—Ä–∞–≤–∏–ª (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
5. JSON-–æ—Ç–≤–µ—Ç —Å–æ —Å–ø–∏—Å–∫–æ–º —Å—É—â–Ω–æ—Å—Ç–µ–π


