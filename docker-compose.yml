services:
  ner-cpu:
    profiles: ["cpu"]
    build:
      context: .
      dockerfile: docker/Dockerfile.cpu
    environment:
      - MODEL_DIR=/models/ner_xlmr_wordlevel_entity
      - LABELS_PATH=/models/ner_xlmr_wordlevel_entity/labels.txt
      - MAX_SEQ_LEN=256
      - BATCH_MAX_SIZE=64
      - BATCH_TIMEOUT_MS=10
      - QUEUE_MAXSIZE=5000
      - REQUEST_TIMEOUT_MS=2000
      - WARMUP_REQUESTS=50
      - USE_QUEUE=true
      - PREPROCESS_ENABLED=false
      - MASK_NUMERIC_BEFORE_NER=true
      - RETURN_DEBUG=false
      - ORT_FORCE_CPU=1
      - ORT_INTRA_OP_NUM_THREADS=8
      - ORT_INTER_OP_NUM_THREADS=1
      - ORT_EXECUTION_MODE_PARALLEL=true
      - PP_TOKEN_INJECT_REGEX=false
      - PP_TOKEN_INJECT_VOLUME_LEVENSHTEIN=true
      - PP_TOKEN_NULLIFY_AFTER_PREPOSITIONS=true
      - PP_TOKEN_NULLIFY_IF_STARTS_WITH_ALL=true
      - PP_TOKEN_ENSURE_LEADING_WORD_O=true
      - PP_WORD_RULES_ENABLED=true
      - PP_WORD_NULLIFY_COUNT_AFTER_PREP=2
      - LOG_LEVEL=DEBUG
      - UVICORN_LOG_LEVEL=debug
    volumes:
      - ../models:/models:rw
    ports:
      - "8000:8000"

  ner-gpu:
    profiles: ["gpu"]
    build:
      context: .
      dockerfile: docker/Dockerfile.gpu
    environment:
      - MODEL_DIR=/models/ner_xlmr_wordlevel_entity
      - LABELS_PATH=/models/ner_xlmr_wordlevel_entity/labels.txt
      - MAX_SEQ_LEN=192
      - BATCH_MAX_SIZE=32
      - BATCH_TIMEOUT_MS=8
      - QUEUE_MAXSIZE=5000
      - REQUEST_TIMEOUT_MS=2000
      - WARMUP_REQUESTS=50
      - USE_QUEUE=true
      - PREPROCESS_ENABLED=false
      - MASK_NUMERIC_BEFORE_NER=true
      - RETURN_DEBUG=false
      - LOG_LEVEL=INFO
      - UVICORN_LOG_LEVEL=info
      - TOKENIZERS_PARALLELISM=false
      - OMP_NUM_THREADS=6
      - OMP_WAIT_POLICY=PASSIVE
      - ORT_INTRA_OP_NUM_THREADS=4
      - ORT_INTER_OP_NUM_THREADS=1
      - ORT_EXECUTION_MODE_PARALLEL=true
      - PP_TOKEN_INJECT_REGEX=True
      - PP_TOKEN_INJECT_VOLUME_LEVENSHTEIN=true
      - PP_TOKEN_NULLIFY_AFTER_PREPOSITIONS=true
      - PP_TOKEN_NULLIFY_IF_STARTS_WITH_ALL=true
      - PP_TOKEN_ENSURE_LEADING_WORD_O=true
      - PP_WORD_RULES_ENABLED=true
      - PP_WORD_NULLIFY_COUNT_AFTER_PREP=2
    volumes:
      - ../models:/models:rw
    ports:
      - "8000:8000"
    gpus: all
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]