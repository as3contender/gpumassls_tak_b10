services:
  ner-cpu:
    profiles: ["cpu"]
    build:
      context: .
      dockerfile: docker/Dockerfile.cpu
    environment:
      - MODEL_DIR=/models/ner_xlmr_wordlevel_entity
      - LABELS_PATH=/models/ner_xlmr_wordlevel_entity/labels.txt
      - MAX_SEQ_LEN=256
      - BATCH_MAX_SIZE=64
      - BATCH_TIMEOUT_MS=10
      - ORT_FORCE_CPU=1
      - LOG_LEVEL=DEBUG
      - UVICORN_LOG_LEVEL=debug
    volumes:
      - ../models:/models:rw
    ports:
      - "8000:8000"

  ner-gpu:
    profiles: ["gpu"]
    build:
      context: .
      dockerfile: docker/Dockerfile.gpu
    environment:
      - MODEL_DIR=/models/ner_xlmr_wordlevel_entity
      - LABELS_PATH=/models/ner_xlmr_wordlevel_entity/labels.txt
      - MAX_SEQ_LEN=256
      - BATCH_MAX_SIZE=64
      - BATCH_TIMEOUT_MS=10
      - ORT_INTRA_OP_NUM_THREADS=4
      - ORT_INTER_OP_NUM_THREADS=1
      - LOG_LEVEL=DEBUG
      - UVICORN_LOG_LEVEL=debug
    volumes:
      - ../models:/models:rw
    ports:
      - "8000:8000"
    gpus: all
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]